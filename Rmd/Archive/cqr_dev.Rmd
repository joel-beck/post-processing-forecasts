---
title: "CQR Variants Development"
author: "Joel Beck"
output:
  bookdown::pdf_document2:
    highlight: tango  # pygments
    toc: FALSE
    number_sections: FALSE
    df_print: tibble
    latex_engine: pdflatex
    keep_tex: FALSE
  bookdown::html_document2:
    theme: flatly
    highlight: pygments  # kate
    toc: TRUE
    toc_float: TRUE
    number_sections: FALSE
    df_print: tibble
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE, fig.align = "center",
  out.width = "100%", dpi = 300, fig.asp = 0.618, collapse = TRUE
)
```

```{r libraries}
library(dplyr)
library(patchwork)
```

# Check Reproducibility

```{r}
# Run this chunk to reproduce old values
# The issue is only contained in the cqr file
# When commenting new fix_quantiles_crossing() function out and replacing new with old cqr file, the result is reproducible !!
# fix_quantiles_crossing() improves cqr result however!!
# Do not forget to add method argument again to update_subset_cqr()
cqr_results_old <- readr::read_rds(here::here("data_results", "uk_cqr.rds"))

devtools::load_all()
cv_init_training <- 0.5
uk_data <- readr::read_csv(
  here::here("data_modified", "uk_data_incidences.csv")
)

complete_models <- uk_data |>
  dplyr::count(model) |>
  dplyr::filter(n == max(n)) |>
  dplyr::pull(model)

df_updated <- update_predictions(
  df = uk_data, methods = "cqr",
  models = complete_models, cv_init_training = cv_init_training, verbose = TRUE
)

cqr_results_new <- df_updated |> collect_predictions()

cqr_results_old |>
  scoringutils::score() |>
  scoringutils::summarise_scores(by = c("method"))

cqr_results_new |>
  scoringutils::score() |>
  scoringutils::summarise_scores(by = c("method"))
```

# Adjust Multiplicative Version

```{r}
cqr3_results <- readr::read_rds(here::here("data_results", "uk_cqr3.rds"))
```

```{r}
model <- "epiforecasts-EpiExpert"
location <- "GB"
target_type <- "Cases"
horizon <- 1
quantile <- 0.05

plot_intervals(
  cqr3_results,
  model = model, target_type = target_type, horizon = horizon, quantile = quantile
)
```

```{r}
df <- readr::read_csv(here::here("data_modified", "uk_data_incidences.csv"))
method <- "cqr_multiplicative"
cv_init_training <- 6

mod <- model
t <- target_type
h <- horizon
q <- quantile
l <- location

df <- df |>
  dplyr::filter(
    .data$model == mod & .data$location == l & .data$target_type == t & .data$horizon == h
  )

quantiles_list <- filter_combination(df, model, location, target_type, horizon, quantile)

# can contain lower quantile predictions of 0
quantiles_low <- quantiles_list$quantiles_low
true_values <- quantiles_list$true_values
quantiles_high <- quantiles_list$quantiles_high

# code of cqr_multiplicative
scores_list <- compute_scores_multiplicative(true_values, quantiles_low, quantiles_high, regularize_scores = FALSE)

# chooses maximum value for 0.05 quantile
# max of true_values / quantiles_low will almost always be greater than 1
# => lower bound will be pushed upwards even if it should not
margin_lower <- compute_margin(scores_list$scores_lower, quantile)
margin_upper <- compute_margin(scores_list$scores_upper, quantile)

list(
  # adjust lower and upper bound with multiplicative margin factor
  margin_lower = margin_lower,
  margin_upper = margin_upper,
  lower_bound = quantiles_low * margin_lower,
  upper_bound = quantiles_high * margin_upper
)
```

```{r}
quantile <- 0.05

true_values <- rep(5, 10)
# here lower quantiles should be adjusted downwards, but margin_lower is greater than 1
quantiles_low <- c(1, 1, rep(1000, 8))
# upper quantiles should be adjusted downwards a lot, but are only adjusted slightly
quantiles_high <- c(5.1, 5.1, rep(1000, 8))

scores_list <- compute_scores_multiplicative(true_values, quantiles_low, quantiles_high, regularize_scores = FALSE)
margin_lower <- compute_margin(scores_list$scores_lower, quantile)
margin_upper <- compute_margin(scores_list$scores_upper, quantile)
```


```{r}
# problem 1: interval gets shifted upwards almost always, lower bound is never pushed down
# idea: constrain the problem to either make the interval larger
# => move lower bound downwards and upper bound upwards
# or smaller
# => move lower bound upwards and upper bound downwards
# could be implemented by forcing the product of margin_lower * margin_upper = 1
margin_lower / sqrt(margin_lower * margin_upper)
margin_upper / sqrt(margin_lower * margin_upper)
```

```{r}
# problem 2: margin is influenced strongly by outliers in score vector
quantile <- 0.05

true_values <- rep(5, 10)
quantiles_low <- c(1, 1, rep(1000, 8))
quantiles_high <- c(1000, 1000, rep(1, 8))

scores_list <- compute_scores_multiplicative(true_values, quantiles_low, quantiles_high, regularize_scores = FALSE)
margin_lower <- compute_margin(scores_list$scores_lower, quantile)
margin_upper <- compute_margin(scores_list$scores_upper, quantile)

# idea: regularize by pulling all entries in score vector closer to 1 but keeps them
# positive
# Potential Candidate: Some kind of (square) root transformation
# Regularization should be stronger, if spread in scores vector is larger
# First approach: Let x = sd(score_vector) => scale by x'th root
regularize_scores <- function(scores) {
  scores^(1 / sd(scores))
}

scores_list$scores_lower
regularize_scores(scores_list$scores_lower)

scores_list$scores_upper
regularize_scores(scores_list$scores_upper)
```


# Compare three CQR methods

```{r}
cqr3_results <- readr::read_rds(here::here("data_results", "uk_cqr3.rds"))

cqr3_results |>
  extract_training_set() |>
  scoringutils::score() |>
  scoringutils::summarise_scores(by = c("method")) |>
  dplyr::select(method:dispersion)

# multiplicative has too high values for dispersion and overprediction
# => makes intervals too large
cqr3_results |>
  extract_validation_set() |>
  scoringutils::score() |>
  scoringutils::summarise_scores(by = c("method")) |>
  dplyr::select(method:dispersion)
```

```{r}
# quantile
df_eval_train <- cqr3_results |> eval_methods(
  summarise_by = "quantile",
  training_set = TRUE
)
df_eval_val <- cqr3_results |> eval_methods(summarise_by = "quantile")

p1 <- plot_eval(df_eval_train)
p2 <- plot_eval(df_eval_val)

p1 + p2
```

```{r}
# horizon
df_eval_train <- cqr3_results |> eval_methods(
  summarise_by = "horizon",
  training_set = TRUE
)
df_eval_val <- cqr3_results |> eval_methods(summarise_by = "horizon")

p1 <- plot_eval(df_eval_train)
p2 <- plot_eval(df_eval_val)

p1 + p2
```

```{r}
# target_type
df_eval_train <- cqr3_results |> eval_methods(
  summarise_by = "target_type",
  training_set = TRUE
)
df_eval_val <- cqr3_results |> eval_methods(summarise_by = "target_type")

p1 <- plot_eval(df_eval_train)
p2 <- plot_eval(df_eval_val)

p1 + p2
```

```{r}
# model
df_eval_train <- cqr3_results |> eval_methods(
  summarise_by = "model",
  training_set = TRUE
)
df_eval_val <- cqr3_results |> eval_methods(summarise_by = "model")

p1 <- plot_eval(df_eval_train)
p2 <- plot_eval(df_eval_val)

p1 + p2
```


# CQR Results for different training-validation splits

```{r}
full_results <- readr::read_rds(here::here("data_results", "uk_cqr3_cv.rds"))

full_results |>
  extract_training_set() |>
  scoringutils::score() |>
  scoringutils::summarise_scores(by = c("cv_init_training", "method")) |>
  dplyr::arrange(cv_init_training) |>
  dplyr::select(cv_init_training:dispersion)

full_results |>
  extract_validation_set() |>
  scoringutils::score() |>
  scoringutils::summarise_scores(by = c("cv_init_training", "method")) |>
  dplyr::arrange(cv_init_training) |>
  dplyr::select(cv_init_training:dispersion):
```

```{r}
# training set
df_eval <- eval_methods(full_results, summarise_by = "cv_init_training", training_set = TRUE)
plot_eval(df_eval)
```

```{r}
# validation set
df_eval <- eval_methods(full_results, summarise_by = "cv_init_training")
plot_eval(df_eval)
```

```{r}
# 0 means no training set, only validation set
df_eval <- eval_methods(full_results, summarise_by = "cv_init_training")
plot_eval(df_eval |> dplyr::select(-cqr_multiplicative))
```
 
```{r}
df_eval <- eval_methods(full_results, summarise_by = "cv_init_training")
plot_eval(
  df_eval |>
    dplyr::select(-cqr_multiplicative) |>
    dplyr::filter(cv_init_training > 0)
)
```
  
 






 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
