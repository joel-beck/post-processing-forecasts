---
output:
  bookdown::pdf_document2:
    includes:
      in_header: preamble.tex
    toc: FALSE
    highlight: tango
    number_sections: TRUE
    df_print: tibble
    latex_engine: pdflatex
bibliography: [paper.bib, packages.bib]
biblio-style: apalike
urlcolor: black
linkcolor: blue
links-as-notes: true
---

# Introduction {#introduction}

Forecasts can play an important role in informing public policy and personal decision making. During the Covid-19 pandemic, for example, governments and public support for political action, relied heavily on predictions of future case and death numbers. As epidemic developments depend on numerous factors including the decision processes of individuals, there is inherent uncertainty in epidemic forecasts. Thus, there is a growing consensus that these infectious disease forecasts should be probabilistic in nature [@bracher2021]. 

Many forecasts, however, tend to be overconfident: A comprehensive review found that observed values were within the $95\%$ confidence intervals for only $75\%$ of predictions [@Gnanvi2021]. One approach to improve forecasts in terms of their confidence interval coverage, is *post-processing*. The idea is to adjust forecast uncertainty in form of prediction quantiles systematically, e.g. by a fixed value or a certain factor based on the percentage of observations which were covered by the prediction intervals in the past.

We apply post processing methods to human forecasts from the UK Covid-19 Crowd Forecasting Challenge as well as model based forecasts provided by the European Covid-19 Forecast Hub. Using these data sets we examine the contributions post-processing techniques can provide and their effects among varying *models*, *target types* (i.e. Covid-19 Cases or Deaths), forecast *horizons* and *quantiles*.

In order to provide a well-organized infrastructure for our analysis, simplify further extensions and provide a basis which other researchers can use to investigate post-processing methods, we developed the `postforecasts` R package. This report introduces the package, its use and provides examples through our analysis of the Covid-19 forecasts.

The report is divided into the following sections: \Cref{analysis-tools} introduces the two data sets and the main functions of the `postforecasts` package. \Cref{cqr} presents post-processing methods based on *Conformalized Quantile Regression*, including a theoretical introduction as well as an analysis of their performance on the data. \Cref{qsa} builds on top of this structure by introducing *Quantile Spread Adjustment* based post-processing methods and explores their results. \Cref{comparison} compares all implemented methods and proposes an ensemble model. Finally, \Cref{conclusion} summarizes the results and discusses their implications.
