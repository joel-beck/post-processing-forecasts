
@article{romano2019,
	title = {Conformalized {Quantile} {Regression}},
	url = {http://arxiv.org/abs/1905.03222},
	abstract = {Conformal prediction is a technique for constructing prediction intervals that attain valid coverage in finite samples, without making distributional assumptions. Despite this appeal, existing conformal methods can be unnecessarily conservative because they form intervals of constant or weakly varying length across the input space. In this paper we propose a new method that is fully adaptive to heteroscedasticity. It combines conformal prediction with classical quantile regression, inheriting the advantages of both. We establish a theoretical guarantee of valid coverage, supplemented by extensive experiments on popular regression datasets. We compare the efficiency of conformalized quantile regression to other conformal methods, showing that our method tends to produce shorter intervals.},
	urldate = {2022-02-25},
	journal = {arXiv:1905.03222 [stat]},
	author = {Romano, Yaniv and Patterson, Evan and Cand√®s, Emmanuel J.},
	month = may,
	year = {2019},
	note = {arXiv: 1905.03222},
	keywords = {Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/joel/Zotero/storage/TWSTGVAB/Romano et al. - 2019 - Conformalized Quantile Regression.pdf:application/pdf;arXiv.org Snapshot:/Users/joel/Zotero/storage/3ZBLXH28/1905.html:text/html},
}

@article{rumack2021,
	title = {Recalibrating probabilistic forecasts of epidemics},
	url = {http://arxiv.org/abs/2112.06305},
	abstract = {Distributional forecasts are important for a wide variety of applications, including forecasting epidemics. Often, forecasts are miscalibrated, or unreliable in assigning uncertainty to future events. We present a recalibration method that can be applied to a black-box forecaster given retrospective forecasts and observations, as well as an extension to make this method more effective in recalibrating epidemic forecasts. This method is guaranteed to improve calibration and log score performance when trained and measured in-sample. We also prove that the increase in expected log score of a recalibrated forecaster is equal to the entropy of the PIT distribution. We apply this recalibration method to the 27 influenza forecasters in the FluSight Network and show that recalibration reliably improves forecast accuracy and calibration. This method is effective, robust, and easy to use as a post-processing tool to improve epidemic forecasts.},
	urldate = {2022-02-25},
	journal = {arXiv:2112.06305 [cs]},
	author = {Rumack, Aaron and Tibshirani, Ryan J. and Rosenfeld, Roni},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.06305},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/joel/Zotero/storage/HJTDE3EG/Rumack et al. - 2021 - Recalibrating probabilistic forecasts of epidemics.pdf:application/pdf;arXiv.org Snapshot:/Users/joel/Zotero/storage/6LBD769Y/2112.html:text/html},
}

@misc{tibshirani2019,
	address = {Carnegie Mellon University},
	title = {Advances and {Challenges} in {Conformal} {Inference}},
	url = {https://www.stat.cmu.edu/~ryantibs/talks/conformal-2019.pdf},
	author = {Tibshirani, Ryan},
	year = {2019},
}

@book{hyndman2021,
	edition = {3},
	title = {Forecasting: principles and practice},
	url = {https://otexts.com/fpp3/},
	publisher = {OTexts},
	author = {Hyndman, Rob and Athanasopoulos, George},
	year = {2021},
}
